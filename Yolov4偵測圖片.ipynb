{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8fe84e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--weights WEIGHTS [WEIGHTS ...]] [--source SOURCE] [--output OUTPUT]\n",
      "                             [--img-size IMG_SIZE] [--conf-thres CONF_THRES] [--iou-thres IOU_THRES] [--device DEVICE]\n",
      "                             [--view-img] [--save-txt] [--classes CLASSES [CLASSES ...]] [--agnostic-nms] [--augment]\n",
      "                             [--update] [--cfg CFG] [--names NAMES]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\p9514\\AppData\\Roaming\\jupyter\\runtime\\kernel-2405964c-b4e5-4af3-a2bb-4352926d31f6.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# %load detect2.py\n",
    "import argparse\n",
    "import os\n",
    "import platform\n",
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:/Program Files/Tesseract-OCR/tesseract.exe\"\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "\n",
    "from utils.google_utils import attempt_load\n",
    "from utils.datasets import LoadStreams, LoadImages\n",
    "from utils.general import (\n",
    "    check_img_size, non_max_suppression, apply_classifier, scale_coords, xyxy2xywh, strip_optimizer)\n",
    "from utils.plots import plot_one_box\n",
    "from utils.torch_utils import select_device, load_classifier, time_synchronized\n",
    "\n",
    "from models.models import *\n",
    "from utils.datasets import *\n",
    "from utils.general import *\n",
    "\n",
    "\n",
    "\n",
    "def load_classes(path):\n",
    "    # Loads *.names file at 'path'\n",
    "    with open(path, 'r') as f:\n",
    "        names = f.read().split('\\n')\n",
    "    return list(filter(None, names))  # filter removes empty strings (such as last line)\n",
    "\n",
    "def detect(save_img=False):\n",
    "    out, source, weights, view_img, save_txt, imgsz, cfg, names = \\\n",
    "        opt.output, opt.source, opt.weights, opt.view_img, opt.save_txt, opt.img_size, opt.cfg, opt.names\n",
    "    webcam = source == '0' or source.startswith('rtsp') or source.startswith('http') or source.endswith('.txt')\n",
    "\n",
    "    # Initialize\n",
    "    device = select_device(opt.device)\n",
    "    if os.path.exists(out):\n",
    "        shutil.rmtree(out)  # delete output folder\n",
    "    os.makedirs(out)  # make new output folder\n",
    "    half = device.type != 'cpu'  # half precision only supported on CUDA\n",
    "\n",
    "    # Load model\n",
    "    model = Darknet(cfg, imgsz).cuda()\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(weights[0], map_location=device)['model'])\n",
    "        #model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "        #imgsz = check_img_size(imgsz, s=model.stride.max())  # check img_size\n",
    "    except:\n",
    "        load_darknet_weights(model, weights[0])\n",
    "    model.to(device).eval()\n",
    "    if half:\n",
    "        model.half()  # to FP16\n",
    "\n",
    "    # Second-stage classifier\n",
    "    classify = False\n",
    "    if classify:\n",
    "        modelc = load_classifier(name='resnet101', n=2)  # initialize\n",
    "        modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model'])  # load weights\n",
    "        modelc.to(device).eval()\n",
    "\n",
    "    # Set Dataloader\n",
    "    vid_path, vid_writer = None, None\n",
    "    if webcam:\n",
    "        view_img = True\n",
    "        cudnn.benchmark = True  # set True to speed up constant image size inference\n",
    "        dataset = LoadStreams(source, img_size=imgsz)\n",
    "    else:\n",
    "        save_img = True\n",
    "        dataset = LoadImages(source, img_size=imgsz, auto_size=64)\n",
    "\n",
    "    # Get names and colors\n",
    "    names = load_classes(names)\n",
    "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]\n",
    "\n",
    "    strings = [] #多數決存放的string\n",
    "    bestimg=0\n",
    "    acccount=0\n",
    "    # Run inference\n",
    "    t0 = time.time()\n",
    "    img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img\n",
    "    _ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once\n",
    "    for path, img, im0s, vid_cap in dataset:\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "\n",
    "        # Inference\n",
    "        t1 = time_synchronized()\n",
    "        pred = model(img, augment=opt.augment)[0]\n",
    "\n",
    "        # Apply NMS\n",
    "        pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)\n",
    "        t2 = time_synchronized()\n",
    "\n",
    "        # Apply Classifier\n",
    "        if classify:\n",
    "            pred = apply_classifier(pred, modelc, img, im0s)\n",
    "\n",
    "        # Process detections\n",
    "        for i, det in enumerate(pred):  # detections per image\n",
    "            if webcam:  # batch_size >= 1\n",
    "                p, s, im0 = path[i], '%g: ' % i, im0s[i].copy()\n",
    "            else:\n",
    "                p, s, im0 = path, '', im0s\n",
    "           \n",
    "           \n",
    "            \n",
    "\n",
    "            save_path = str(Path(out) / Path(p).name)\n",
    "            txt_path = str(Path(out) / Path(p).stem) + ('_%g' % dataset.frame if dataset.mode == 'video' else '')\n",
    "            s += '%gx%g ' % img.shape[2:]  # print string\n",
    "            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "            if det is not None and len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "                # Print results\n",
    "                for c in det[:, -1].unique():\n",
    "                    n = (det[:, -1] == c).sum()  # detections per class\n",
    "                    s += '%g %ss, ' % (n, names[int(c)])  # add to string\n",
    "\n",
    "                # Write results\n",
    "                for *xyxy, conf, cls in det:\n",
    "                    if save_txt:  # Write to file\n",
    "                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
    "                        with open(txt_path + '.txt', 'a') as f:\n",
    "                            f.write(('%g ' * 5 + '\\n') % (cls, *xywh))  # label format\n",
    "                    if save_img:# 裁剪檢測框區域\n",
    "                        x1, y1, x2, y2 = map(int, xyxy)\n",
    "                        cropped_img = im0[y1:y2, x1:x2]\n",
    "                         # 儲存裁剪後的圖片\n",
    "                        save_cropped_path = save_path.replace('.jpg', f'_{int(x1)}_{int(y1)}_{int(x2)}_{int(y2)}.jpg')\n",
    "                        cv2.imwrite(save_cropped_path, cropped_img)\n",
    "                        gray_img = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)\n",
    "                        _, binary_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "                        denoised_img = cv2.fastNlMeansDenoising(binary_img, None, 10, 7, 21)\n",
    "                        enhanced_img = cv2.equalizeHist(denoised_img)# enhanced_img = cv2.bitwise_not(enhanced_img)\n",
    "                        pil_img = Image.fromarray(enhanced_img)  \n",
    "                        text = pytesseract.image_to_string(pil_img, lang='eng', config='--psm 6 --oem 1 ')  # 英文文字檢測\n",
    "                        allowed_chars = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789')\n",
    "                        text_filtered = ''.join(filter(allowed_chars.__contains__, text)).upper()\n",
    "                        #print(\"Detected Text:\", text_filtered)\n",
    "                        cv2.putText(im0, text_filtered, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "                    def calculate_formula_result(letters):\n",
    "                        values = {\n",
    "                                    'A': 10, 'B': 12, 'C': 13, 'D': 14, 'E': 15, 'F': 16, 'G': 17, 'H': 18, 'I': 19, 'J': 20,\n",
    "                                    'K': 21, 'L': 23, 'M': 24, 'N': 25, 'O': 26, 'P': 27, 'Q': 28, 'R': 29, 'S': 30, 'T': 31,\n",
    "                                    'U': 32, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, '1': 1,  '2':  2,'3':3,'4':4,'5':5,'6':6,'7':7,'8':8,'9':9\n",
    "                                }\n",
    "                        total = 0\n",
    "                        for i, letter in enumerate(letters):\n",
    "                            if letter in values:\n",
    "                                total += values[letter] * (2 ** i)\n",
    "                        return total % 11  \n",
    "                    \n",
    "\n",
    "\n",
    "                    # path1 =\"C:/Users/p9514/YOLOv4/data/output/SEKU5875349\"\n",
    "                    # countimg = 0\n",
    "                    # for i in os.listdir(path1):\n",
    "                    #     countimg = countimg+1  \n",
    "                    \n",
    "                    def find_most_common_char(string):   # 多數決\n",
    "                        char_count = {}\n",
    "                        for char in string:\n",
    "                            if char in char_count:\n",
    "                                char_count[char] += 1\n",
    "                            else:\n",
    "                                char_count[char] = 1\n",
    "\n",
    "                        max_count = 0\n",
    "                        most_common_char = ''\n",
    "\n",
    "                        for char, count in char_count.items():\n",
    "                            if count > max_count:\n",
    "                                max_count = count\n",
    "                                most_common_char = char\n",
    "                                bestimg = max_count\n",
    "\n",
    "                            # if bestimg >0 :\n",
    "                            \n",
    "                            #     print(\"績效為:\",bestimg/countimg)\n",
    "                            #     break\n",
    "                        return most_common_char,max_count\n",
    "                    \n",
    "\n",
    "\n",
    "                    \n",
    "                        \n",
    "                        \n",
    "                    input_letters = text_filtered\n",
    "                    input_letters = input_letters[:10]\n",
    "                    # result = calculate_formula_result(input_letters)\n",
    "                    # print(\"Detected Text:\", input_letters)\n",
    "                    # print(result,type(result))\n",
    "                    print(\"讀取圖片名稱:\",save_path[-15:-4])\n",
    "                    # if  result == int(save_path[-5]):\n",
    "                    print(\"偵測貨櫃號:\", input_letters)\n",
    "                    # print(result)\n",
    "                    \n",
    "                    \n",
    "                    if input_letters==save_path[-15:-5]:\n",
    "                        acccount=acccount+1\n",
    "                    print(\"預測績效:\",acccount/35)\n",
    "                    \n",
    "\n",
    "\n",
    "                    \n",
    "                            \n",
    "                # print(strings)\n",
    "                    # print(\"出現最多次數的貨號\",find_most_common_char(strings))\n",
    "                        \n",
    "                        \n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "                    # if view_img:# 裁剪檢測框區域\n",
    "                    #     x1, y1, x2, y2 = map(int, xyxy)\n",
    "                    #     cropped_view = im0[y1:y2, x1:x2]\n",
    "                    #      # 儲存裁剪後的圖片\n",
    "                    #     save_cropped_path = save_path.replace('.mkv', f'_{int(x1)}_{int(y1)}_{int(x2)}_{int(y2)}.mkv')\n",
    "                    #     cv2.imwrite(save_cropped_path, cropped_view)\n",
    "                    #     gray_img = cv2.cvtColor(cropped_view, cv2.COLOR_BGR2GRAY)\n",
    "                    #     _, binary_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "                    #     denoised_img = cv2.fastNlMeansDenoising(binary_img, None, 10, 7, 21)\n",
    "                    #     enhanced_img = cv2.equalizeHist(denoised_img)# enhanced_img = cv2.bitwise_not(enhanced_img)\n",
    "                    #     pil_img = Image.fromarray(enhanced_img)  \n",
    "                    #     text = pytesseract.image_to_string(pil_img, lang='eng')  # 英文文字檢測\n",
    "                    #     allowed_chars = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789')\n",
    "                    #     text_filtered = ''.join(filter(allowed_chars.__contains__, text)).upper()\n",
    "                    #     print(\"Detected Text:\", text_filtered)\n",
    "                    #     cv2.putText(im0, text_filtered, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "                if save_img or view_img:  # Add bbox to image\n",
    "                    label = '%s %.2f' % (names[int(cls)], conf)\n",
    "                    plot_one_box(xyxy, im0, color=colors[int(cls)], line_thickness=3)\n",
    "\n",
    "            # Print time (inference + NMS)\n",
    "            print('%sDone. (%.3fs)' % (s, t2 - t1))\n",
    "\n",
    "            # Stream results\n",
    "            if view_img:\n",
    "                cv2.imshow(p, im0)\n",
    "                if cv2.waitKey(1) == ord('q'):  # q to quit\n",
    "                    raise StopIteration\n",
    "\n",
    "            # Save results (image with detections)\n",
    "            if save_img:\n",
    "                if dataset.mode == 'images':\n",
    "                    cv2.imwrite(save_path, im0)\n",
    "                else:\n",
    "                    if vid_path != save_path:  # new video\n",
    "                        vid_path = save_path\n",
    "                        if isinstance(vid_writer, cv2.VideoWriter):\n",
    "                            vid_writer.release()  # release previous video writer\n",
    "\n",
    "                        fourcc = 'mp4v'  # output video codec\n",
    "                        fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "                        w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                        h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                        vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*fourcc), fps, (w, h))\n",
    "                    vid_writer.write(im0)\n",
    "\n",
    "    if save_txt or save_img:\n",
    "        print('Results saved to %s' % Path(out))\n",
    "        if platform == 'darwin' and not opt.update:  # MacOS\n",
    "            os.system('open ' + save_path)\n",
    "\n",
    "    print('Done. (%.3fs)' % (time.time() - t0))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--weights', nargs='+', type=str, default='yolov4.weights', help='model.pt path(s)')\n",
    "    parser.add_argument('--source', type=str, default='inference/images', help='source')  # file/folder, 0 for webcam\n",
    "    parser.add_argument('--output', type=str, default='inference/output', help='output folder')  # output folder\n",
    "    parser.add_argument('--img-size', type=int, default=640, help='inference size (pixels)')\n",
    "    parser.add_argument('--conf-thres', type=float, default=0.8, help='object confidence threshold')\n",
    "    parser.add_argument('--iou-thres', type=float, default=0.5, help='IOU threshold for NMS')\n",
    "    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
    "    parser.add_argument('--view-img', action='store_true', help='display results')\n",
    "    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')\n",
    "    parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --class 0, or --class 0 2 3')\n",
    "    parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')\n",
    "    parser.add_argument('--augment', action='store_true', help='augmented inference')\n",
    "    parser.add_argument('--update', action='store_true', help='update all models')\n",
    "    parser.add_argument('--cfg', type=str, default='models/yolov4.cfg', help='*.cfg path')\n",
    "    parser.add_argument('--names', type=str, default='data/coco.names', help='*.cfg path')\n",
    "    opt = parser.parse_args()\n",
    "    print(opt)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if opt.update:  # update all models (to fix SourceChangeWarning)\n",
    "            for opt.weights in ['']:\n",
    "                detect()\n",
    "                strip_optimizer(opt.weights)\n",
    "        else:\n",
    "            detect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a14fcda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(weights=['weights/yolo-obj_best.weights'], source='data/accimg/', output='inference/output', img_size=640, conf_thres=0.8, iou_thres=0.5, device='', view_img=False, save_txt=False, classes=None, agnostic_nms=False, augment=False, update=False, cfg='models/yolov4.cfg', names='data/coco.names')\n",
      "image 1/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\FFAU2895947.jpg: 讀取圖片名稱: FFAU2895947\n",
      "偵測貨櫃號: FAU2895947\n",
      "預測績效: 0.0\n",
      "384x640 1 persons, Done. (0.274s)\n",
      "image 2/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\MAGU5605323 .jpg: 讀取圖片名稱: AGU5605323 \n",
      "偵測貨櫃號: MAU0009323\n",
      "預測績效: 0.0\n",
      "384x640 1 persons, Done. (0.274s)\n",
      "image 3/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\SEKU5875349.jpg: 讀取圖片名稱: SEKU5875349\n",
      "偵測貨櫃號: SEKU587534\n",
      "預測績效: 0.02857142857142857\n",
      "384x640 1 persons, Done. (0.274s)\n",
      "image 4/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\SEKU5877491.jpg: 讀取圖片名稱: SEKU5877491\n",
      "偵測貨櫃號: SEKU87749T\n",
      "預測績效: 0.02857142857142857\n",
      "384x640 1 persons, Done. (0.274s)\n",
      "image 5/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\SEKU6026686.jpg: 讀取圖片名稱: SEKU6026686\n",
      "偵測貨櫃號: SEKU602694\n",
      "預測績效: 0.02857142857142857\n",
      "384x640 1 persons, Done. (0.273s)\n",
      "image 6/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\TCNU6246126.jpg: 讀取圖片名稱: TCNU6246126\n",
      "偵測貨櫃號: ICNU624612\n",
      "預測績效: 0.02857142857142857\n",
      "384x640 1 persons, Done. (0.273s)\n",
      "image 7/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\TLLU4080736.jpg: 讀取圖片名稱: TLLU4080736\n",
      "偵測貨櫃號: TLLU408073\n",
      "預測績效: 0.05714285714285714\n",
      "讀取圖片名稱: TLLU4080736\n",
      "偵測貨櫃號: 408074561\n",
      "預測績效: 0.05714285714285714\n",
      "384x640 2 persons, Done. (0.272s)\n",
      "image 8/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\TRHU8927462.jpg: 讀取圖片名稱: TRHU8927462\n",
      "偵測貨櫃號: TRHU892746\n",
      "預測績效: 0.08571428571428572\n",
      "讀取圖片名稱: TRHU8927462\n",
      "偵測貨櫃號: I992746456\n",
      "預測績效: 0.08571428571428572\n",
      "384x640 2 persons, Done. (0.273s)\n",
      "image 9/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\TSSU5017340.jpg: 讀取圖片名稱: TSSU5017340\n",
      "偵測貨櫃號: VSOUUTESG4\n",
      "預測績效: 0.08571428571428572\n",
      "讀取圖片名稱: TSSU5017340\n",
      "偵測貨櫃號: VVICOSDJ50\n",
      "預測績效: 0.08571428571428572\n",
      "384x640 2 persons, Done. (0.273s)\n",
      "image 10/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\TSSU5029819.jpg: 讀取圖片名稱: TSSU5029819\n",
      "偵測貨櫃號: TSSU502981\n",
      "預測績效: 0.11428571428571428\n",
      "384x640 1 persons, Done. (0.273s)\n",
      "image 11/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\TSSU5042071.jpg: 讀取圖片名稱: TSSU5042071\n",
      "偵測貨櫃號: TSSU504207\n",
      "預測績效: 0.14285714285714285\n",
      "384x640 1 persons, Done. (0.272s)\n",
      "image 12/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\TSSU5061615.jpg: 讀取圖片名稱: TSSU5061615\n",
      "偵測貨櫃號: ISSU506161\n",
      "預測績效: 0.14285714285714285\n",
      "讀取圖片名稱: TSSU5061615\n",
      "偵測貨櫃號: WU50616145\n",
      "預測績效: 0.14285714285714285\n",
      "384x640 2 persons, Done. (0.272s)\n",
      "image 13/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\TSSU5099400.jpg: 讀取圖片名稱: TSSU5099400\n",
      "偵測貨櫃號: TSSU509940\n",
      "預測績效: 0.17142857142857143\n",
      "讀取圖片名稱: TSSU5099400\n",
      "偵測貨櫃號: U509944561\n",
      "預測績效: 0.17142857142857143\n",
      "384x640 2 persons, Done. (0.275s)\n",
      "image 14/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\TSSU5142300.jpg: 讀取圖片名稱: TSSU5142300\n",
      "偵測貨櫃號: TSSU\n",
      "預測績效: 0.17142857142857143\n",
      "讀取圖片名稱: TSSU5142300\n",
      "偵測貨櫃號: SUS\n",
      "預測績效: 0.17142857142857143\n",
      "384x640 2 persons, Done. (0.274s)\n",
      "image 15/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\TSSU5160351.jpg: 讀取圖片名稱: TSSU5160351\n",
      "偵測貨櫃號: TSSU516035\n",
      "預測績效: 0.2\n",
      "384x640 1 persons, Done. (0.274s)\n",
      "image 16/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\WHLU5591798.jpg: 讀取圖片名稱: WHLU5591798\n",
      "偵測貨櫃號: WHLUSOMAA5\n",
      "預測績效: 0.2\n",
      "384x640 1 persons, Done. (0.272s)\n",
      "image 17/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\WHLU5842825.jpg: 讀取圖片名稱: WHLU5842825\n",
      "偵測貨櫃號: WHU3842824\n",
      "預測績效: 0.2\n",
      "384x640 1 persons, Done. (0.274s)\n",
      "image 18/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\WHSU2483178.jpg: 讀取圖片名稱: WHSU2483178\n",
      "偵測貨櫃號: WHSU248317\n",
      "預測績效: 0.22857142857142856\n",
      "384x640 1 persons, Done. (0.273s)\n",
      "image 19/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\WHSU2615314.jpg: 讀取圖片名稱: WHSU2615314\n",
      "偵測貨櫃號: NHSU261531\n",
      "預測績效: 0.22857142857142856\n",
      "384x640 1 persons, Done. (0.271s)\n",
      "image 20/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\WHSU2864765.jpg: 讀取圖片名稱: WHSU2864765\n",
      "偵測貨櫃號: WHSU286471\n",
      "預測績效: 0.22857142857142856\n",
      "讀取圖片名稱: WHSU2864765\n",
      "偵測貨櫃號: Y286471261\n",
      "預測績效: 0.22857142857142856\n",
      "384x640 2 persons, Done. (0.275s)\n",
      "image 21/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\WHSU5295430.jpg: 讀取圖片名稱: WHSU5295430\n",
      "偵測貨櫃號: WHSU529543\n",
      "預測績效: 0.2571428571428571\n",
      "384x640 1 persons, Done. (0.273s)\n",
      "image 22/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\WHSU5368199.jpg: 讀取圖片名稱: WHSU5368199\n",
      "偵測貨櫃號: WHSU536819\n",
      "預測績效: 0.2857142857142857\n",
      "讀取圖片名稱: WHSU5368199\n",
      "偵測貨櫃號: U53681A561\n",
      "預測績效: 0.2857142857142857\n",
      "384x640 2 persons, Done. (0.272s)\n",
      "image 23/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\WHSU5563298.jpg: 讀取圖片名稱: WHSU5563298\n",
      "偵測貨櫃號: NHSU556329\n",
      "預測績效: 0.2857142857142857\n",
      "384x640 1 persons, Done. (0.273s)\n",
      "image 24/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\WHSU5610492.jpg: 讀取圖片名稱: WHSU5610492\n",
      "偵測貨櫃號: WHSU56AC\n",
      "預測績效: 0.2857142857142857\n",
      "384x640 1 persons, Done. (0.271s)\n",
      "image 25/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\WHSU5628589.jpg: 讀取圖片名稱: WHSU5628589\n",
      "偵測貨櫃號: WHSU562888\n",
      "預測績效: 0.2857142857142857\n",
      "讀取圖片名稱: WHSU5628589\n",
      "偵測貨櫃號: ISUSH2858J\n",
      "預測績效: 0.2857142857142857\n",
      "384x640 2 persons, Done. (0.272s)\n",
      "image 26/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\WHSU5744465.jpg: 讀取圖片名稱: WHSU5744465\n",
      "偵測貨櫃號: VHSUJBREAS\n",
      "預測績效: 0.2857142857142857\n",
      "384x640 1 persons, Done. (0.273s)\n",
      "image 27/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\WHSU5991104.jpg: 讀取圖片名稱: WHSU5991104\n",
      "偵測貨櫃號: WHSU599110\n",
      "預測績效: 0.3142857142857143\n",
      "384x640 1 persons, Done. (0.273s)\n",
      "image 28/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\WHSU5998393.jpg: 讀取圖片名稱: WHSU5998393\n",
      "偵測貨櫃號: HSU899039Q\n",
      "預測績效: 0.3142857142857143\n",
      "讀取圖片名稱: WHSU5998393\n",
      "偵測貨櫃號: UY59903456\n",
      "預測績效: 0.3142857142857143\n",
      "384x640 2 persons, Done. (0.272s)\n",
      "image 29/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\WHSU6010260.jpg: 讀取圖片名稱: WHSU6010260\n",
      "偵測貨櫃號: WHSU601026\n",
      "預測績效: 0.34285714285714286\n",
      "讀取圖片名稱: WHSU6010260\n",
      "偵測貨櫃號: SUSOWARC\n",
      "預測績效: 0.34285714285714286\n",
      "384x640 2 persons, Done. (0.273s)\n",
      "image 30/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\WHSU6040178.jpg: 讀取圖片名稱: WHSU6040178\n",
      "偵測貨櫃號: WHSUSOSOHA\n",
      "預測績效: 0.34285714285714286\n",
      "384x640 1 persons, Done. (0.275s)\n",
      "image 31/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\WHSU6052306.jpg: 讀取圖片名稱: WHSU6052306\n",
      "偵測貨櫃號: WHOLD52545\n",
      "預測績效: 0.34285714285714286\n",
      "讀取圖片名稱: WHSU6052306\n",
      "偵測貨櫃號: SU60525456\n",
      "預測績效: 0.34285714285714286\n",
      "384x640 2 persons, Done. (0.274s)\n",
      "image 32/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\WHSU6167120.jpg: 讀取圖片名稱: WHSU6167120\n",
      "偵測貨櫃號: WHSU616712\n",
      "預測績效: 0.37142857142857144\n",
      "384x640 1 persons, Done. (0.275s)\n",
      "image 33/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\WHSU6557387.jpg: 讀取圖片名稱: WHSU6557387\n",
      "偵測貨櫃號: NSU655738A\n",
      "預測績效: 0.37142857142857144\n",
      "384x640 1 persons, Done. (0.273s)\n",
      "image 34/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\WHSU6651665.jpg: 讀取圖片名稱: WHSU6651665\n",
      "偵測貨櫃號: SRA6A5G1\n",
      "預測績效: 0.37142857142857144\n",
      "384x640 1 persons, Done. (0.274s)\n",
      "image 35/35 C:\\Users\\p9514\\YOLOv4\\data\\accimg\\WHSU6856285.jpg: 讀取圖片名稱: WHSU6856285\n",
      "偵測貨櫃號: WHSU\n",
      "預測績效: 0.37142857142857144\n",
      "384x640 1 persons, Done. (0.273s)\n",
      "Results saved to inference\\output\n",
      "Done. (19.156s)\n"
     ]
    }
   ],
   "source": [
    "%run detect2.py --weights weights/yolo-obj_best.weights --source data/accimg/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9e07a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
